{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_223004/3951502023.py:10: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  places = pd.read_csv('data/clean_places.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218096, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>spans</th>\n",
       "      <th>country_predicted</th>\n",
       "      <th>country_conf</th>\n",
       "      <th>admin1</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>country_code3</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>place_name</th>\n",
       "      <th>feature_class</th>\n",
       "      <th>feature_code</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shanghai</td>\n",
       "      <td>[{'start': 162, 'end': 170}]</td>\n",
       "      <td>CHN</td>\n",
       "      <td>0.963741</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>31.22222</td>\n",
       "      <td>121.45806</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1796236.0</td>\n",
       "      <td>Shanghai</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>4963912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aeromonas</td>\n",
       "      <td>[{'start': 1153, 'end': 1162}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4729030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>[{'start': 57, 'end': 65}]</td>\n",
       "      <td>THA</td>\n",
       "      <td>0.948191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.50000</td>\n",
       "      <td>101.00000</td>\n",
       "      <td>THA</td>\n",
       "      <td>1605651.0</td>\n",
       "      <td>Kingdom of Thailand</td>\n",
       "      <td>A</td>\n",
       "      <td>PCLI</td>\n",
       "      <td>4695222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangkok</td>\n",
       "      <td>[{'start': 302, 'end': 309}]</td>\n",
       "      <td>THA</td>\n",
       "      <td>0.961249</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>13.75398</td>\n",
       "      <td>100.50144</td>\n",
       "      <td>THA</td>\n",
       "      <td>1609350.0</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLC</td>\n",
       "      <td>4695222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Israel</td>\n",
       "      <td>[{'start': 285, 'end': 291}]</td>\n",
       "      <td>ISR</td>\n",
       "      <td>0.948191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.50000</td>\n",
       "      <td>34.75000</td>\n",
       "      <td>ISR</td>\n",
       "      <td>294640.0</td>\n",
       "      <td>State of Israel</td>\n",
       "      <td>A</td>\n",
       "      <td>PCLI</td>\n",
       "      <td>4762134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word                           spans country_predicted  country_conf  \\\n",
       "0   Shanghai    [{'start': 162, 'end': 170}]               CHN      0.963741   \n",
       "5  Aeromonas  [{'start': 1153, 'end': 1162}]               NaN      0.000000   \n",
       "6   Thailand      [{'start': 57, 'end': 65}]               THA      0.948191   \n",
       "7    Bangkok    [{'start': 302, 'end': 309}]               THA      0.961249   \n",
       "9     Israel    [{'start': 285, 'end': 291}]               ISR      0.948191   \n",
       "\n",
       "     admin1       lat        lon country_code3  geonameid  \\\n",
       "0  Shanghai  31.22222  121.45806           CHN  1796236.0   \n",
       "5       NaN       NaN        NaN           NaN        NaN   \n",
       "6       NaN  15.50000  101.00000           THA  1605651.0   \n",
       "7   Bangkok  13.75398  100.50144           THA  1609350.0   \n",
       "9       NaN  31.50000   34.75000           ISR   294640.0   \n",
       "\n",
       "            place_name feature_class feature_code   doc_id  \n",
       "0             Shanghai             P         PPLA  4963912  \n",
       "5                  NaN           NaN          NaN  4729030  \n",
       "6  Kingdom of Thailand             A         PCLI  4695222  \n",
       "7              Bangkok             P         PPLC  4695222  \n",
       "9      State of Israel             A         PCLI  4762134  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we load our location data and drop any duplicated places within documents\n",
    "import pandas as pd\n",
    "import shapely.vectorized\n",
    "from global_land_mask import globe\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# Load location data \n",
    "places = pd.read_csv('data/clean_places.csv')                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "places = places.drop_duplicates([\"doc_id\",\"geonameid\"]) \n",
    "print(places.shape)\n",
    "places.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>0 - relevant</th>\n",
       "      <th>2 - 1.02. Changes in temperature</th>\n",
       "      <th>2 - 1.03. Seasonal change</th>\n",
       "      <th>2 - 1.04. Changes in precipitation</th>\n",
       "      <th>2 - 1.06. Climate change (unspecified)</th>\n",
       "      <th>2 - 1.07. Other meteorological variables</th>\n",
       "      <th>...</th>\n",
       "      <th>4 - 2.04. Extreme event attribution</th>\n",
       "      <th>4 - 2.05. Scenarios</th>\n",
       "      <th>5 - 4.01. Floods and drought</th>\n",
       "      <th>5 - 4.02. Heatwaves</th>\n",
       "      <th>5 - 4.03. Wildfires</th>\n",
       "      <th>5 - 4.04. Other extreme events</th>\n",
       "      <th>5 - 4.05. Extreme cold</th>\n",
       "      <th>6 - 5.01. Pollution</th>\n",
       "      <th>6 - 5.03. Reduced agricultural &amp; aquaculture productivity</th>\n",
       "      <th>6 - 5.04. Reduced labour and physical capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W2021823358</td>\n",
       "      <td>Projections of heat waves with high impact on ...</td>\n",
       "      <td>Climate change will result in more intense, mo...</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W2129447349</td>\n",
       "      <td>Apparent Temperature and Cause-Specific Mortal...</td>\n",
       "      <td>Temperature, a key climate change indicator, i...</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W2345489509</td>\n",
       "      <td>Climate Change and the Emergent Epidemic of CK...</td>\n",
       "      <td>Climate change has led to significant rise of ...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W2093213412</td>\n",
       "      <td>Children are likely to suffer most from our fo...</td>\n",
       "      <td>BACKGROUND: The periods of fetal and child dev...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W615562828</td>\n",
       "      <td>Autochthonous Chikungunya Transmission and Ext...</td>\n",
       "      <td>Background Extreme precipitation events are in...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "0  W2021823358  Projections of heat waves with high impact on ...   \n",
       "1  W2129447349  Apparent Temperature and Cause-Specific Mortal...   \n",
       "2  W2345489509  Climate Change and the Emergent Epidemic of CK...   \n",
       "3  W2093213412  Children are likely to suffer most from our fo...   \n",
       "4   W615562828  Autochthonous Chikungunya Transmission and Ext...   \n",
       "\n",
       "                                            abstract  publication_year  \\\n",
       "0  Climate change will result in more intense, mo...            2014.0   \n",
       "1  Temperature, a key climate change indicator, i...            2011.0   \n",
       "2  Climate change has led to significant rise of ...            2016.0   \n",
       "3  BACKGROUND: The periods of fetal and child dev...            2008.0   \n",
       "4  Background Extreme precipitation events are in...            2015.0   \n",
       "\n",
       "   0 - relevant  2 - 1.02. Changes in temperature  2 - 1.03. Seasonal change  \\\n",
       "0           1.0                               1.0                        0.0   \n",
       "1           1.0                               1.0                        0.0   \n",
       "2           1.0                               1.0                        0.0   \n",
       "3           1.0                               1.0                        0.0   \n",
       "4           1.0                               0.0                        0.0   \n",
       "\n",
       "   2 - 1.04. Changes in precipitation  2 - 1.06. Climate change (unspecified)  \\\n",
       "0                                 0.0                                     0.0   \n",
       "1                                 0.0                                     0.0   \n",
       "2                                 0.0                                     0.0   \n",
       "3                                 0.0                                     0.0   \n",
       "4                                 1.0                                     0.0   \n",
       "\n",
       "   2 - 1.07. Other meteorological variables  ...  \\\n",
       "0                                       1.0  ...   \n",
       "1                                       0.0  ...   \n",
       "2                                       0.0  ...   \n",
       "3                                       0.0  ...   \n",
       "4                                       0.0  ...   \n",
       "\n",
       "   4 - 2.04. Extreme event attribution  4 - 2.05. Scenarios  \\\n",
       "0                                  1.0                  1.0   \n",
       "1                                  0.0                  0.0   \n",
       "2                                  1.0                  0.0   \n",
       "3                                  0.0                  0.0   \n",
       "4                                  0.0                  0.0   \n",
       "\n",
       "   5 - 4.01. Floods and drought  5 - 4.02. Heatwaves  5 - 4.03. Wildfires  \\\n",
       "0                           0.0                  1.0                  0.0   \n",
       "1                           0.0                  0.0                  0.0   \n",
       "2                           0.0                  1.0                  0.0   \n",
       "3                           0.0                  0.0                  0.0   \n",
       "4                           0.0                  0.0                  0.0   \n",
       "\n",
       "   5 - 4.04. Other extreme events  5 - 4.05. Extreme cold  \\\n",
       "0                             0.0                     0.0   \n",
       "1                             0.0                     0.0   \n",
       "2                             0.0                     0.0   \n",
       "3                             0.0                     0.0   \n",
       "4                             0.0                     0.0   \n",
       "\n",
       "   6 - 5.01. Pollution  \\\n",
       "0                  0.0   \n",
       "1                  0.0   \n",
       "2                  0.0   \n",
       "3                  0.0   \n",
       "4                  0.0   \n",
       "\n",
       "   6 - 5.03. Reduced agricultural & aquaculture productivity  \\\n",
       "0                                                0.0           \n",
       "1                                                0.0           \n",
       "2                                                0.0           \n",
       "3                                                0.0           \n",
       "4                                                0.0           \n",
       "\n",
       "   6 - 5.04. Reduced labour and physical capacity  \n",
       "0                                             1.0  \n",
       "1                                             0.0  \n",
       "2                                             0.0  \n",
       "3                                             0.0  \n",
       "4                                             0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_feather(\"data/included_studies.feather\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-178.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-176.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-173.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-171.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-168.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LAT     LON\n",
       "0 -88.75 -178.75\n",
       "1 -88.75 -176.25\n",
       "2 -88.75 -173.75\n",
       "3 -88.75 -171.25\n",
       "4 -88.75 -168.75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def generate_grid_df(degrees):\n",
    "    '''\n",
    "    Generate a dataframe with a grid of of cells degrees x degrees\n",
    "    '''\n",
    "    LON = np.linspace(-180+degrees*0.5,180-degrees*0.5,int(360/degrees))\n",
    "    LAT = np.linspace(-90+degrees*0.5,90-degrees*0.5,int(180/degrees))\n",
    "    lon_df, lat_df = np.meshgrid(LON,LAT)\n",
    "\n",
    "    return pd.DataFrame({\"LAT\": lat_df.ravel(), \"LON\": lon_df.ravel()})\n",
    "    \n",
    "grid_df = generate_grid_df(2.5)\n",
    "grid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/.local/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_223004/1055013544.py:2: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas\n"
     ]
    }
   ],
   "source": [
    "import cartopy.io.shapereader as shpreader\n",
    "import geopandas\n",
    "# First we define a list of the shapefile definitions we want\n",
    "shpfiles = [\n",
    "    dict(resolution='50m', category='cultural', name='admin_0_countries'),\n",
    "    dict(resolution='10m', category='cultural', name='admin_1_states_provinces'),\n",
    "    dict(resolution='10m', category='physical', name='geography_regions_polys'),\n",
    "    dict(resolution='10m', category='physical', name='geography_marine_polys')\n",
    "    #\"data/gadm36_1.shp\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading shapefile {'resolution': '50m', 'category': 'cultural', 'name': 'admin_0_countries'}\n",
      "reading shapefile {'resolution': '10m', 'category': 'cultural', 'name': 'admin_1_states_provinces'}\n",
      "reading shapefile {'resolution': '10m', 'category': 'physical', 'name': 'geography_regions_polys'}\n",
      "reading shapefile {'resolution': '10m', 'category': 'physical', 'name': 'geography_marine_polys'}\n"
     ]
    }
   ],
   "source": [
    "# We'll start an empty dataframe to store our shapefile-grid matches\n",
    "shp_grid_df = pd.DataFrame()\n",
    "\n",
    "# Now we download the shapefiles and combine into one large geopandas dataframe\n",
    "shp_df  = None\n",
    "for shpfilename in shpfiles:\n",
    "    print(f\"reading shapefile {shpfilename}\")\n",
    "    if shp_df is None:\n",
    "        shp_df = geopandas.read_file(shpreader.natural_earth(**shpfilename))\n",
    "    else:\n",
    "        shp_df = shp_df.merge(geopandas.read_file(shpreader.natural_earth(**shpfilename)),how=\"outer\")\n",
    "    time.sleep(10) # Wait a bit before downloading the next shapefile so we do not make too many requests too quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shpfile_id</th>\n",
       "      <th>grid_df_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shpfile_id  grid_df_id\n",
       "0           0        4114\n",
       "1           0        3971\n",
       "2           0        4115\n",
       "3           0        3972\n",
       "4           0        4116"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "degrees = 2.5\n",
    "\n",
    "# We are going to store our shapefile-gridcell index matches here\n",
    "shp_grid = []\n",
    "\n",
    "# This is the grid we will work with\n",
    "yv, xv = np.meshgrid(grid_df.LAT.unique(), grid_df.LON.unique())\n",
    "for i, place in shp_df.iterrows(): # Now we go through all the shapes\n",
    "    # show which gridcell centers are contained inside the shape\n",
    "    # ignore the warning caused by shapely using an old version of numpy\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        inplace = shapely.vectorized.contains(place.geometry, xv, yv)\n",
    "    idx = np.argwhere(inplace)\n",
    "    # Get the number of cells contained in the shape\n",
    "    number_cells = idx.size/2\n",
    "    if number_cells == 0:\n",
    "        # If we have no cell centers in the shape, get the shape center and the cell which contains it\n",
    "        c = place.geometry.centroid\n",
    "        lon = c.x//degrees*degrees+degrees*0.5\n",
    "        lat = c.y//degrees*degrees+degrees*0.5\n",
    "        da_df = grid_df[(grid_df['LON']==lon) & (grid_df['LAT']==lat)]\n",
    "        shp_grid.append({\"shpfile_id\": i, \"grid_df_id\": da_df.index[0]})\n",
    "    else:\n",
    "        for point in idx:\n",
    "            lon = grid_df.LON.unique()[point[0]]\n",
    "            lat = grid_df.LAT.unique()[point[1]]\n",
    "            da_df = grid_df[(grid_df['LON']==lon) & (grid_df['LAT']==lat)]\n",
    "            shp_grid.append({\"shpfile_id\": i, \"grid_df_id\": da_df.index[0]}) \n",
    "\n",
    "shp_grid_df = pd.DataFrame.from_dict(shp_grid)\n",
    "    \n",
    "\n",
    "shp_grid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapping = {\n",
    "    \"ADM1\": [\"Admin-1 scale rank\", \"Admin-1 aggregation\", \"Admin-1 minor island\"],\n",
    "    \"PCLI\": [\"Admin-0 country\"],\n",
    "    'MTS': ['Range/mtn'],\n",
    "    'PLAT': ['Plateau'],\n",
    "    'PLN': ['Plain'],\n",
    "    'DSRT': ['Desert'],\n",
    "    'OCN': ['ocean'],\n",
    "    'SEA': ['sea', 'bay'],\n",
    "    'GULF': ['gulf', 'bay'],\n",
    "    'BAY': ['gulf', 'bay'],\n",
    "    'CHN': ['channel'],\n",
    "    'BSNU': ['basin']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add all the other codes we don't cover with blank shapefile classes\n",
    "for fcode in places.feature_code.unique():\n",
    "    if fcode not in feature_mapping:\n",
    "        feature_mapping[fcode] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_223004/2263670162.py:43: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  places[\"place_name\"] = places[\"place_name\"].str.lower().str.replace(\"mts.\",\"mountains\")\n",
      "/tmp/ipykernel_223004/2263670162.py:44: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  shp_df[\"name\"] = shp_df[\"name\"].str.lower().str.replace(\"mts.\",\"mountains\")\n"
     ]
    }
   ],
   "source": [
    "# To help match, we will rename some shapes so that they are the same as the name in our database\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Altay\", case=False)),\"name\"] = \"Altay\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Appalach\", case=False)),\"name\"] = \"Appalachian Mountains\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"cant\", case=False)),\"name\"] = \"Cordillera Cantábrica\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Dabie\", case=False)),\"name\"] = \"Dabie Shan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"EASTERN GHATS\", case=False)),\"name\"] = \"Eastern Ghāts\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"WESTERN GHATS\", case=False)),\"name\"] = \"Western Ghāts\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"kunlun\", case=False)),\"name\"] = \"Kalakunlun Shan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"LEN MOUNTAIN\", case=False)),\"name\"] = \"Kölen\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Taihang Mts.\", case=False)),\"name\"] = \"Taihang Shan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Tatra Mts.\", case=False)),\"name\"] = \"Tatry\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"TIAN SHAN\", case=False)),\"name\"] = \"Tien Shan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"andes\", case=False)),\"name\"] = \"Andes Mountains\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"HINDU KUSH\", case=False)),\"name\"] = \"Hindū Kush\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Marrah Mts\", case=False)),\"name\"] = \"Jabal Marrah\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"Lebanon\", case=False)),\"name\"] = \"Mount Lebanon\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Range/mtn\") & (shp_df[\"name\"].str.contains(\"KARAKORAM RA\", case=False)),\"name\"] = \"Karakorum Shan\"\n",
    "\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Desert\") & (shp_df[\"name\"].str.contains(\"Negev\", case=False)), \"name\"] = \"Negev\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Desert\") & (shp_df[\"name\"].str.contains(\"Atacama\", case=False)), \"name\"] = \"Atacama Desert\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Desert\") & (shp_df[\"name\"].str.contains(\"CHIHUAHUAN DESERT\", case=False)), \"name\"] = \"Chihuahua Desert\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Desert\") & (shp_df[\"name\"].str.contains(\"Lut desert\", case=False)), \"name\"] = \"God-e Lut\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Desert\") & (shp_df[\"name\"].str.contains(\"TAKLIMAKAN DESERT\", case=False)), \"name\"] = \"Takla Makan Desert\"\n",
    "\n",
    "shp_df.loc[\n",
    "    (shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"cumberland\", case=False)),[\"name\",\"featurecla\"]\n",
    "] = [\"Cumberland Plateau\", \"Plain\"]\n",
    "shp_df.loc[\n",
    "    (shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"colorado\", case=False)),[\"name\",\"featurecla\"]\n",
    "] = [\"San Francisco Plateau\", \"Plain\"]\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plain\") & (shp_df[\"name\"].str.contains(\"gange\", case=False)),\"name\"] = \"Gangetic Plain\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plain\") & (shp_df[\"name\"].str.contains(\"north china\", case=False)),\"name\"] = \"Huanghuai Pingyuan\"\n",
    "\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"mongol\", case=False)), \"name\"] = \"Nei Mongol Gaoyuan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"deccan\", case=False)), \"name\"] = \"Deccan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"chota\", case=False)), \"name\"] = \"Chota Nāgpur Plateau\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"loess\", case=False)), \"name\"] = \"Huangtu Gaoyuan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"khorat\", case=False)), \"name\"] = \"Khorat Plateau\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"tibet\", case=False)), \"name\"] = \"Qing Zang Gaoyuan\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"polar\", case=False)), \"name\"] = \"South Polar Plateau\"\n",
    "shp_df.loc[(shp_df[\"featurecla\"]==\"Plateau\") & (shp_df[\"name\"].str.contains(\"YUNGUI\", case=False)), \"name\"] = \"Yungui Gaoyuan\"\n",
    "\n",
    "places[\"place_name\"] = places[\"place_name\"].str.lower().str.replace(\"mts.\",\"mountains\") \n",
    "shp_df[\"name\"] = shp_df[\"name\"].str.lower().str.replace(\"mts.\",\"mountains\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADM1\n",
      "PCLI\n",
      "MTS\n",
      "PLAT\n",
      "PLN\n",
      "DSRT\n",
      "OCN\n",
      "SEA\n",
      "GULF\n",
      "BAY\n",
      "CHN\n",
      "BSNU\n",
      "PPLA\n",
      "nan\n",
      "PPLC\n",
      "ADM3\n",
      "CONT\n",
      "AREA\n",
      "ADM2\n",
      "ISL\n",
      "PPLA3\n",
      "AIRP\n",
      "RGN\n",
      "PPL\n",
      "PCLD\n",
      "BLDG\n",
      "PPLA2\n",
      "HTL\n",
      "PPLX\n",
      "LIBR\n",
      "DPR\n",
      "ADMD\n",
      "STM\n",
      "ISLS\n",
      "CTHSE\n",
      "PRK\n",
      "HSP\n",
      "CMTY\n",
      "DIP\n",
      "PPLL\n",
      "CH\n",
      "STNB\n",
      "RSV\n",
      "SHRN\n",
      "MN\n",
      "ADM4\n",
      "ITTR\n",
      "SCHC\n",
      "PEN\n",
      "MUS\n",
      "LK\n",
      "SCH\n",
      "COVE\n",
      "PCLS\n",
      "TOWR\n",
      "MSSN\n",
      "ADM1H\n",
      "LNDF\n",
      "PPLA4\n",
      "RESF\n",
      "AIRH\n",
      "RSD\n",
      "MT\n",
      "RSVT\n",
      "PK\n",
      "CNL\n",
      "PMPW\n",
      "ST\n",
      "RGNE\n",
      "PPLQ\n",
      "STNM\n",
      "CST\n",
      "VLC\n",
      "HSTS\n",
      "FCL\n",
      "USGE\n",
      "PCLF\n",
      "FRST\n",
      "DAM\n",
      "PPLF\n",
      "RESN\n",
      "PCLH\n",
      "BANK\n",
      "AIRF\n",
      "HMSD\n",
      "LCTY\n",
      "DLTA\n",
      "SWT\n",
      "OILF\n",
      "PT\n",
      "WTRH\n",
      "EST\n",
      "AIRQ\n",
      "VAL\n",
      "BCH\n",
      "PCLIX\n",
      "UPLD\n",
      "HSE\n",
      "ADM3H\n",
      "RD\n",
      "MNMT\n",
      "CMPRF\n",
      "RSTN\n",
      "RECG\n",
      "HLL\n",
      "GAP\n",
      "STMC\n",
      "PPLG\n",
      "DEVH\n",
      "MALL\n",
      "CMP\n",
      "AGRF\n",
      "FRM\n",
      "GLCR\n",
      "SALT\n",
      "PPLW\n",
      "WLL\n",
      "ADM2H\n",
      "TMB\n",
      "PPLH\n",
      "HSPC\n",
      "RES\n",
      "ADMF\n",
      "WAD\n",
      "ZN\n",
      "PPLA5\n",
      "MFG\n",
      "PO\n",
      "UNIV\n",
      "HLLS\n",
      "MSQE\n",
      "INDS\n",
      "TRL\n",
      "FLDI\n",
      "BUSTP\n",
      "ADM4H\n",
      "RR\n",
      "TRIG\n",
      "INSM\n",
      "RDJCT\n",
      "GHSE\n",
      "STDM\n",
      "RGNH\n",
      "BLDO\n",
      "WRCK\n",
      "LTHSE\n",
      "STMI\n",
      "PS\n",
      "DTCHI\n",
      "RET\n",
      "SCRP\n",
      "PYR\n",
      "BTL\n",
      "PSH\n",
      "BUSTN\n",
      "COMC\n",
      "CAPE\n",
      "SPNG\n",
      "LOCK\n",
      "PND\n",
      "STMD\n",
      "DCK\n",
      "FT\n",
      "SQR\n",
      "STNE\n",
      "ATOL\n",
      "CTRS\n",
      "STMM\n",
      "HUT\n",
      "HBR\n",
      "LEV\n",
      "DUNE\n",
      "RDGE\n",
      "UNIP\n",
      "TMPL\n",
      "SHSE\n",
      "CNLA\n",
      "CLDA\n",
      "RKS\n",
      "CMPO\n",
      "RDGU\n",
      "BDG\n",
      "LKN\n",
      "TRGU\n",
      "ADM5\n",
      "SMSU\n",
      "MSTY\n",
      "LAVA\n",
      "RESV\n",
      "RK\n",
      "STMB\n",
      "RECR\n",
      "MAR\n",
      "MTRO\n",
      "TRB\n",
      "SLP\n",
      "RNCH\n",
      "ANS\n",
      "RSTNQ\n",
      "STRT\n",
      "FLLS\n",
      "PASS\n",
      "LDGU\n",
      "SCHT\n",
      "PAL\n",
      "MRSHN\n",
      "CHNM\n",
      "SMU\n",
      "AIRB\n",
      "ML\n",
      "RSRT\n",
      "RSTP\n",
      "AIRS\n",
      "PRT\n",
      "ESTX\n",
      "GRAZ\n",
      "TERR\n",
      "GOVL\n",
      "SHSU\n",
      "TRANT\n",
      "LKNI\n",
      "MNQR\n",
      "SWMP\n",
      "SHFU\n",
      "CNFL\n",
      "CAVE\n",
      "ATHF\n",
      "SHOR\n",
      "GATE\n",
      "CTRR\n",
      "RESW\n",
      "SCNU\n",
      "NTK\n",
      "BRKS\n",
      "BCN\n",
      "WTLD\n",
      "FLTT\n",
      "LKS\n",
      "LAND\n",
      "ISLET\n",
      "RSVI\n",
      "MOOR\n",
      "CRKT\n",
      "FYT\n",
      "ESTO\n",
      "CDAU\n",
      "RRQ\n",
      "CMPQ\n",
      "WTRW\n",
      "QUAY\n",
      "OBS\n",
      "PIER\n",
      "ESTSG\n",
      "STNR\n",
      "PP\n",
      "CRTR\n",
      "CAPG\n",
      "MLWND\n",
      "FRMT\n",
      "CRNT\n",
      "BNK\n",
      "SHOL\n",
      "ANCH\n",
      "MKT\n",
      "CTRA\n",
      "SD\n",
      "CTRM\n",
      "CNLSB\n",
      "GRGE\n",
      "FJD\n",
      "LKI\n",
      "CULT\n",
      "LDNG\n",
      "STMX\n",
      "INLT\n",
      "BNKU\n",
      "BAR\n",
      "LGN\n",
      "ADM5H\n",
      "REST\n",
      "PAN\n",
      "BP\n",
      "ESTY\n",
      "HLT\n",
      "RFU\n",
      "WHRF\n",
      "RF\n",
      "OAS\n",
      "MGV\n",
      "TREE\n",
      "LKX\n",
      "PSTP\n",
      "OBPT\n",
      "FSR\n",
      "RHSE\n",
      "PLTU\n",
      "RVN\n",
      "STMA\n",
      "PRKHQ\n",
      "AGRC\n",
      "SPA\n",
      "CLF\n",
      "POOL\n",
      "LKC\n",
      "RUIN\n",
      "RFC\n",
      "ZOO\n",
      "AQC\n",
      "SCHM\n",
      "STLMT\n",
      "STNS\n",
      "ISLF\n",
      "DTCH\n",
      "KRST\n",
      "OVF\n",
      "CTRCM\n",
      "FLD\n",
      "CVNT\n",
      "ISLX\n",
      "WTRC\n",
      "THTR\n",
      "PANS\n",
      "FRMQ\n",
      "MRSH\n",
      "MND\n",
      "(5136418, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_df_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>shp_id</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>6281</td>\n",
       "      <td>5249722</td>\n",
       "      <td>1710</td>\n",
       "      <td>'asir region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>6281</td>\n",
       "      <td>5110789</td>\n",
       "      <td>1710</td>\n",
       "      <td>'asir region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>6281</td>\n",
       "      <td>3927578</td>\n",
       "      <td>1710</td>\n",
       "      <td>'asir region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>6281</td>\n",
       "      <td>3313720</td>\n",
       "      <td>1710</td>\n",
       "      <td>'asir region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>6281</td>\n",
       "      <td>W2291458255</td>\n",
       "      <td>1710</td>\n",
       "      <td>'asir region</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      grid_df_id       doc_id shp_id         place\n",
       "5608        6281      5249722   1710  'asir region\n",
       "5608        6281      5110789   1710  'asir region\n",
       "5608        6281      3927578   1710  'asir region\n",
       "5608        6281      3313720   1710  'asir region\n",
       "5608        6281  W2291458255   1710  'asir region"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll start off with an empty dataframe\n",
    "shp_df_matches = pd.DataFrame()\n",
    "\n",
    "# And define the grid box size\n",
    "degrees = 2.5\n",
    "\n",
    "# Now we want to look through the feature type dictionary we had before\n",
    "for place_key, shpfile_keys in feature_mapping.items():\n",
    "    \n",
    "    print(place_key)\n",
    "    \n",
    "    # We can get all the places and all the shapes\n",
    "    feature_places = places.loc[places[\"feature_code\"]==place_key]\n",
    "    feature_shapes = shp_df.loc[shp_df[\"featurecla\"].isin(shpfile_keys)]\n",
    "    \n",
    "    # And loop through the places\n",
    "    for place, group in feature_places.groupby(\"place_name\"):\n",
    "        # If we don't have a shapefile feature type we just take the grid cell containing the point\n",
    "        if not shpfile_keys:\n",
    "            shp_id = None # we set shp_id to None, round the coordinates, and take the gridcell which has these coordinates\n",
    "            lon = group.lon.values[0]//degrees*degrees+degrees*0.5\n",
    "            lat = group.lat.values[0]//degrees*degrees+degrees*0.5\n",
    "            grid_df_ids = grid_df[(grid_df['LON']==lon) & (grid_df['LAT']==lat)].index\n",
    "\n",
    "        else:\n",
    "            # Otherwise, we are going to try to find the places which match\n",
    "            place_shapes = pd.DataFrame()\n",
    "            # First we will try by geoname ids, if we have these\n",
    "            if feature_shapes[\"gn_id\"].sum() > 0:\n",
    "                place_shapes = feature_shapes.loc[\n",
    "                    (feature_shapes[\"gn_id\"]==group.geonameid.values[0])\n",
    "                ]\n",
    "            # Then we try by country code, if we are dealing with a country\n",
    "            if place_shapes.shape[0]==0 and place_key==\"PCLI\":\n",
    "                place_shapes = feature_shapes.loc[\n",
    "                    feature_shapes[\"ADM0_A3\"] == group.country_predicted.values[0]\n",
    "                ]\n",
    "            # Then we try by name\n",
    "            if place_shapes.shape[0]==0:       \n",
    "                place_shapes = feature_shapes.loc[\n",
    "                    (feature_shapes.name == place)\n",
    "                ]    \n",
    "\n",
    "            if place_shapes.shape[0]==0:\n",
    "                continue # These are the places we cannot match, we need to develop other strategies for these, e.g. using other shapefile libraries\n",
    "    #            if key==\"ADM1\": # can also try using gadm data, which we need to download separately\n",
    "    #                 place_shapes = adm1shps_alt[\n",
    "    #                     (adm1shps_alt[\"NAME_1\"]==group.place_name.values[0]) |\n",
    "    #                     (adm1shps_alt[\"VARNAME_1\"].str.contains(group.place_name.values[0]))\n",
    "    #                 ]\n",
    "            else:\n",
    "                shp_id = place_shapes.index[0]\n",
    "                grid_df_ids = shp_grid_df.loc[\n",
    "                    (shp_grid_df[\"shpfile_id\"]==shp_id),\n",
    "                    \"grid_df_id\"\n",
    "                ]\n",
    "        # For each document with this place, we add a row for each grid cell index matching the place\n",
    "        for did in group.doc_id.unique():\n",
    "            shp_df_matches = pd.concat([\n",
    "                shp_df_matches,\n",
    "                pd.DataFrame.from_dict({\n",
    "                    \"grid_df_id\": grid_df_ids,\n",
    "                    \"doc_id\": [did] * len(grid_df_ids),\n",
    "                    \"shp_id\": [shp_id] * len(grid_df_ids),\n",
    "                    \"place\": place\n",
    "                })\n",
    "            ])\n",
    "            \n",
    "            \n",
    "print(shp_df_matches.shape)\n",
    "shp_df_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_df_matches.to_csv(\"data/shp_df_matches.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-178.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-176.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-173.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-171.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-168.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10363</th>\n",
       "      <td>88.75</td>\n",
       "      <td>168.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10364</th>\n",
       "      <td>88.75</td>\n",
       "      <td>171.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10365</th>\n",
       "      <td>88.75</td>\n",
       "      <td>173.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10366</th>\n",
       "      <td>88.75</td>\n",
       "      <td>176.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10367</th>\n",
       "      <td>88.75</td>\n",
       "      <td>178.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10368 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LAT     LON  population\n",
       "0     -88.75 -178.75         0.0\n",
       "1     -88.75 -176.25         0.0\n",
       "2     -88.75 -173.75         0.0\n",
       "3     -88.75 -171.25         0.0\n",
       "4     -88.75 -168.75         0.0\n",
       "...      ...     ...         ...\n",
       "10363  88.75  168.75         0.0\n",
       "10364  88.75  171.25         0.0\n",
       "10365  88.75  173.75         0.0\n",
       "10366  88.75  176.25         0.0\n",
       "10367  88.75  178.75         0.0\n",
       "\n",
       "[10368 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rioxarray\n",
    "\n",
    "rds = rioxarray.open_rasterio(\"data/gpw_v4_population_count_rev11_2020_1_deg.asc\",\n",
    ")\n",
    "\n",
    "rds = rds.squeeze().drop(\"spatial_ref\").drop(\"band\")\n",
    "rds.name = \"population\"\n",
    "pop_df = rds.to_dataframe().reset_index()\n",
    "\n",
    "pop_df['LAT'] = pop_df['y']//2.5*2.5+1.25\n",
    "pop_df['LON'] = pop_df['x']//2.5*2.5+1.25\n",
    "pop_df.loc[pop_df['population']==-9999,\"population\"]=np.NaN\n",
    "pop_df = pop_df.groupby([\"LAT\",\"LON\"])['population'].sum().reset_index()\n",
    "pop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def area_cell(lat, lon, degrees): \n",
    "    # calculate the area of a gridcell given the center lat and lon and the size in degrees\n",
    "    if lon <0:\n",
    "        lon+=360\n",
    "    R = 6371\n",
    "    f0 = math.radians(lat-degrees*0.5)\n",
    "    f1 = math.radians(lat+degrees*0.5)\n",
    "    l0 = math.radians(lon-degrees*0.5)\n",
    "    l1 = math.radians(lon+degrees*0.5)\n",
    "\n",
    "    return (math.sin(f1)-math.sin(f0)) * (l1 - l0) * R**2\n",
    "\n",
    "\n",
    "grid_df['area'] = grid_df.apply(lambda x: area_cell(x['LAT'], x['LON'], 2.5), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.625, 1.25 , 1.875, 2.5  ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,2.5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_masks = []\n",
    "n = 5\n",
    "land_array = np.empty((grid_df.shape[0], n*n))\n",
    "i = 0\n",
    "for x in np.linspace(0,2.5,n):\n",
    "    for y in np.linspace(0,2.5,n):\n",
    "        land_array[:,i] = globe.is_land(grid_df.LAT+y-1.25, grid_df.LON+x-1.25)\n",
    "        i+=1\n",
    "        \n",
    "land_mask = land_array.sum(axis=1)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df['is_land'] = land_mask\n",
    "grid_df.loc[grid_df['LAT']<-60,'is_land'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3311"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df.is_land.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>area</th>\n",
       "      <th>is_land</th>\n",
       "      <th>precip_da</th>\n",
       "      <th>temp_da</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-178.75</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-176.25</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-173.75</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-171.25</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-88.75</td>\n",
       "      <td>-168.75</td>\n",
       "      <td>1685.654015</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LAT     LON         area  is_land  precip_da  temp_da  population\n",
       "0 -88.75 -178.75  1685.654015    False        NaN      NaN         0.0\n",
       "1 -88.75 -176.25  1685.654015    False        NaN      NaN         0.0\n",
       "2 -88.75 -173.75  1685.654015    False        NaN      NaN         0.0\n",
       "3 -88.75 -171.25  1685.654015    False        NaN      NaN         0.0\n",
       "4 -88.75 -168.75  1685.654015    False        NaN      NaN         0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncc_data = pd.read_csv(\"data/2_merged_da_data.csv\")\n",
    "grid_df = grid_df.merge(\n",
    "    ncc_data[[\"LAT\",\"LON\",\"updated_precip\",\"updated_temp\"]].rename(columns={\"updated_precip\": \"precip_da\", \"updated_temp\": \"temp_da\"})\n",
    ").merge(pop_df)\n",
    "grid_df.reset_index().to_csv(\"data/grid_df.csv\", index=False)\n",
    "grid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df = pd.read_csv(\"data/grid_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "\n",
    "rds = rioxarray.open_rasterio(\"data/gpw_v4_population_count_rev11_2020_1_deg.asc\",\n",
    ")\n",
    "\n",
    "rds = rds.squeeze().drop(\"spatial_ref\").drop(\"band\")\n",
    "rds.name = \"population\"\n",
    "pop_df = rds.to_dataframe().reset_index()\n",
    "\n",
    "pop_df['LAT'] = pop_df['y']//2.5*2.5+1.25\n",
    "pop_df['LON'] = pop_df['x']//2.5*2.5+1.25\n",
    "pop_df.loc[pop_df['population']==-9999,\"population\"]=np.NaN\n",
    "pop_df = pop_df.merge(grid_df, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>population</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>index</th>\n",
       "      <th>area</th>\n",
       "      <th>is_land</th>\n",
       "      <th>precip_da</th>\n",
       "      <th>temp_da</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89.5</td>\n",
       "      <td>-179.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.75</td>\n",
       "      <td>-178.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89.5</td>\n",
       "      <td>-178.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.75</td>\n",
       "      <td>-178.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.5</td>\n",
       "      <td>-177.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.75</td>\n",
       "      <td>-176.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.5</td>\n",
       "      <td>-176.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.75</td>\n",
       "      <td>-176.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.5</td>\n",
       "      <td>-175.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.75</td>\n",
       "      <td>-176.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64795</th>\n",
       "      <td>-89.5</td>\n",
       "      <td>175.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-88.75</td>\n",
       "      <td>176.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64796</th>\n",
       "      <td>-89.5</td>\n",
       "      <td>176.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-88.75</td>\n",
       "      <td>176.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64797</th>\n",
       "      <td>-89.5</td>\n",
       "      <td>177.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-88.75</td>\n",
       "      <td>178.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64798</th>\n",
       "      <td>-89.5</td>\n",
       "      <td>178.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-88.75</td>\n",
       "      <td>178.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64799</th>\n",
       "      <td>-89.5</td>\n",
       "      <td>179.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-88.75</td>\n",
       "      <td>178.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y      x  population    LAT     LON  index  area is_land  precip_da  \\\n",
       "0      89.5 -179.5         NaN  88.75 -178.75    NaN   NaN     NaN        NaN   \n",
       "1      89.5 -178.5         NaN  88.75 -178.75    NaN   NaN     NaN        NaN   \n",
       "2      89.5 -177.5         NaN  88.75 -176.25    NaN   NaN     NaN        NaN   \n",
       "3      89.5 -176.5         NaN  88.75 -176.25    NaN   NaN     NaN        NaN   \n",
       "4      89.5 -175.5         NaN  88.75 -176.25    NaN   NaN     NaN        NaN   \n",
       "...     ...    ...         ...    ...     ...    ...   ...     ...        ...   \n",
       "64795 -89.5  175.5         NaN -88.75  176.25    NaN   NaN     NaN        NaN   \n",
       "64796 -89.5  176.5         NaN -88.75  176.25    NaN   NaN     NaN        NaN   \n",
       "64797 -89.5  177.5         NaN -88.75  178.75    NaN   NaN     NaN        NaN   \n",
       "64798 -89.5  178.5         NaN -88.75  178.75    NaN   NaN     NaN        NaN   \n",
       "64799 -89.5  179.5         NaN -88.75  178.75    NaN   NaN     NaN        NaN   \n",
       "\n",
       "       temp_da  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "64795      NaN  \n",
       "64796      NaN  \n",
       "64797      NaN  \n",
       "64798      NaN  \n",
       "64799      NaN  \n",
       "\n",
       "[64800 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['featurecla', 'scalerank', 'LABELRANK', 'SOVEREIGNT', 'SOV_A3',\n",
       "       'ADM0_DIF', 'LEVEL', 'TYPE', 'ADMIN', 'ADM0_A3', 'GEOU_DIF', 'GEOUNIT',\n",
       "       'GU_A3', 'SU_DIF', 'SUBUNIT', 'SU_A3', 'BRK_DIFF', 'NAME', 'NAME_LONG',\n",
       "       'BRK_A3', 'BRK_NAME', 'BRK_GROUP', 'ABBREV', 'POSTAL', 'FORMAL_EN',\n",
       "       'FORMAL_FR', 'NAME_CIAWF', 'NOTE_ADM0', 'NOTE_BRK', 'NAME_SORT',\n",
       "       'NAME_ALT', 'MAPCOLOR7', 'MAPCOLOR8', 'MAPCOLOR9', 'MAPCOLOR13',\n",
       "       'POP_EST', 'POP_RANK', 'GDP_MD_EST', 'POP_YEAR', 'LASTCENSUS',\n",
       "       'GDP_YEAR', 'ECONOMY', 'INCOME_GRP', 'WIKIPEDIA', 'FIPS_10_', 'ISO_A2',\n",
       "       'ISO_A3', 'ISO_A3_EH', 'ISO_N3', 'UN_A3', 'WB_A2', 'WB_A3', 'WOE_ID',\n",
       "       'WOE_ID_EH', 'WOE_NOTE', 'ADM0_A3_IS', 'ADM0_A3_US', 'ADM0_A3_UN',\n",
       "       'ADM0_A3_WB', 'CONTINENT', 'REGION_UN', 'SUBREGION', 'REGION_WB',\n",
       "       'NAME_LEN', 'LONG_LEN', 'ABBREV_LEN', 'TINY', 'HOMEPART', 'MIN_ZOOM',\n",
       "       'MIN_LABEL', 'MAX_LABEL', 'NE_ID', 'WIKIDATAID', 'NAME_AR', 'NAME_BN',\n",
       "       'NAME_DE', 'NAME_EN', 'NAME_ES', 'NAME_FR', 'NAME_EL', 'NAME_HI',\n",
       "       'NAME_HU', 'NAME_ID', 'NAME_IT', 'NAME_JA', 'NAME_KO', 'NAME_NL',\n",
       "       'NAME_PL', 'NAME_PT', 'NAME_RU', 'NAME_SV', 'NAME_TR', 'NAME_VI',\n",
       "       'NAME_ZH', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = geopandas.read_file(shpreader.natural_earth(\n",
    "    **dict(resolution='50m', category='cultural', name='admin_0_countries')\n",
    "))\n",
    "countries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>featurecla</th>\n",
       "      <th>scalerank</th>\n",
       "      <th>LABELRANK</th>\n",
       "      <th>SOVEREIGNT</th>\n",
       "      <th>SOV_A3</th>\n",
       "      <th>ADM0_DIF</th>\n",
       "      <th>LEVEL</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>ADMIN</th>\n",
       "      <th>ADM0_A3</th>\n",
       "      <th>...</th>\n",
       "      <th>NAME_KO</th>\n",
       "      <th>NAME_NL</th>\n",
       "      <th>NAME_PL</th>\n",
       "      <th>NAME_PT</th>\n",
       "      <th>NAME_RU</th>\n",
       "      <th>NAME_SV</th>\n",
       "      <th>NAME_TR</th>\n",
       "      <th>NAME_VI</th>\n",
       "      <th>NAME_ZH</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Admin-0 country</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Sovereign country</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>...</td>\n",
       "      <td>ì§ë°ë¸ì¨</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZimbÃ¡bue</td>\n",
       "      <td>ÐÐ¸Ð¼Ð±Ð°Ð±Ð²Ðµ</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>Zimbabve</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>è¾å·´å¨</td>\n",
       "      <td>POLYGON ((31.28789 -22.40205, 31.19727 -22.344...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Admin-0 country</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Sovereign country</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>...</td>\n",
       "      <td>ì ë¹ì</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZÃ¢mbia</td>\n",
       "      <td>ÐÐ°Ð¼Ð±Ð¸Ñ</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>Zambiya</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>èµæ¯äº</td>\n",
       "      <td>POLYGON ((30.39609 -15.64307, 30.25068 -15.643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Admin-0 country</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>YEM</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Sovereign country</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>YEM</td>\n",
       "      <td>...</td>\n",
       "      <td>ìë©</td>\n",
       "      <td>Jemen</td>\n",
       "      <td>Jemen</td>\n",
       "      <td>IÃ©men</td>\n",
       "      <td>ÐÐµÐ¼ÐµÐ½</td>\n",
       "      <td>Jemen</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>ä¹é¨</td>\n",
       "      <td>MULTIPOLYGON (((53.08564 16.64839, 52.58145 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Admin-0 country</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>VNM</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Sovereign country</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>VNM</td>\n",
       "      <td>...</td>\n",
       "      <td>ë² í¸ë¨</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Wietnam</td>\n",
       "      <td>Vietname</td>\n",
       "      <td>ÐÑÐµÑÐ½Ð°Ð¼</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Viá»t Nam</td>\n",
       "      <td>è¶å</td>\n",
       "      <td>MULTIPOLYGON (((104.06396 10.39082, 104.08301 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Admin-0 country</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>VEN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Sovereign country</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>VEN</td>\n",
       "      <td>...</td>\n",
       "      <td>ë² ë¤ììë¼</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Wenezuela</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>ÐÐµÐ½ÐµÑÑÑÐ»Ð°</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>å§å",
       "§çæ</td>\n",
       "      <td>MULTIPOLYGON (((-60.82119 9.13838, -60.94141 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        featurecla  scalerank  LABELRANK SOVEREIGNT SOV_A3  ADM0_DIF  LEVEL  \\\n",
       "0  Admin-0 country          1          3   Zimbabwe    ZWE         0      2   \n",
       "1  Admin-0 country          1          3     Zambia    ZMB         0      2   \n",
       "2  Admin-0 country          1          3      Yemen    YEM         0      2   \n",
       "3  Admin-0 country          3          2    Vietnam    VNM         0      2   \n",
       "4  Admin-0 country          5          3  Venezuela    VEN         0      2   \n",
       "\n",
       "                TYPE      ADMIN ADM0_A3  ...          NAME_KO    NAME_NL  \\\n",
       "0  Sovereign country   Zimbabwe     ZWE  ...     ì§ë°ë¸ì¨   Zimbabwe   \n",
       "1  Sovereign country     Zambia     ZMB  ...        ì ë¹ì     Zambia   \n",
       "2  Sovereign country      Yemen     YEM  ...           ìë©      Jemen   \n",
       "3  Sovereign country    Vietnam     VNM  ...        ë² í¸ë¨    Vietnam   \n",
       "4  Sovereign country  Venezuela     VEN  ...  ë² ë¤ììë¼  Venezuela   \n",
       "\n",
       "     NAME_PL    NAME_PT             NAME_RU    NAME_SV    NAME_TR     NAME_VI  \\\n",
       "0   Zimbabwe  ZimbÃ¡bue    ÐÐ¸Ð¼Ð±Ð°Ð±Ð²Ðµ   Zimbabwe   Zimbabve    Zimbabwe   \n",
       "1     Zambia    ZÃ¢mbia        ÐÐ°Ð¼Ð±Ð¸Ñ     Zambia    Zambiya      Zambia   \n",
       "2      Jemen     IÃ©men          ÐÐµÐ¼ÐµÐ½      Jemen      Yemen       Yemen   \n",
       "3    Wietnam   Vietname      ÐÑÐµÑÐ½Ð°Ð¼    Vietnam    Vietnam  Viá»t Nam   \n",
       "4  Wenezuela  Venezuela  ÐÐµÐ½ÐµÑÑÑÐ»Ð°  Venezuela  Venezuela   Venezuela   \n",
       "\n",
       "        NAME_ZH                                           geometry  \n",
       "0     è¾å·´å¨  POLYGON ((31.28789 -22.40205, 31.19727 -22.344...  \n",
       "1     èµæ¯äº  POLYGON ((30.39609 -15.64307, 30.25068 -15.643...  \n",
       "2        ä¹é¨  MULTIPOLYGON (((53.08564 16.64839, 52.58145 16...  \n",
       "3        è¶å  MULTIPOLYGON (((104.06396 10.39082, 104.08301 ...  \n",
       "4  å§å\n",
       "§çæ  MULTIPOLYGON (((-60.82119 9.13838, -60.94141 9...  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = 1\n",
    "\n",
    "# We are going to store our shapefile-gridcell index matches here\n",
    "shp_grid = []\n",
    "\n",
    "# This is the grid we will work with\n",
    "yv, xv = np.meshgrid(pop_df.y.unique(), pop_df.x.unique())\n",
    "for i, place in countries.iterrows(): # Now we go through all the shapes\n",
    "    # show which gridcell centers are contained inside the shape\n",
    "    # ignore the warning caused by shapely using an old version of numpy\n",
    "    for offset in [-degrees*0.5, degrees*0.5, 0]:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            inplace = shapely.vectorized.contains(place.geometry, xv+offset, yv+offset)\n",
    "        idx = np.argwhere(inplace)\n",
    "        # Get the number of cells contained in the shape\n",
    "        number_cells = idx.size/2\n",
    "        if number_cells == 0:\n",
    "            # If we have no cell centers in the shape, get the shape center and the cell which contains it\n",
    "            c = place.geometry.centroid\n",
    "            lon = c.x//degrees*degrees+degrees*0.5\n",
    "            lat = c.y//degrees*degrees+degrees*0.5\n",
    "            pop_df.loc[(pop_df['x']==lon) & (pop_df['y']==lat),\"country\"] = place[\"ISO_A3\"]\n",
    "        else:\n",
    "            for point in idx:\n",
    "                lon = pop_df.x.unique()[point[0]]\n",
    "                lat = pop_df.y.unique()[point[1]]\n",
    "                pop_df.loc[(pop_df['x']==lon) & (pop_df['y']==lat),\"country\"] = place[\"ISO_A3\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174186820.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_df[pd.isna(pop_df[\"country\"])][\"population\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "polygons = []\n",
    "for x in pop_df.x:\n",
    "    for y in pop_df.y:\n",
    "        polygons.append(Polygon([\n",
    "            (x-degrees*0.5,y-degrees*0.5), (x+degrees*0.5, y-degrees*0.5), \n",
    "            (x+degrees*0.5,y+degrees*0.5), (x-degrees*0.5, y+degrees*0.5)\n",
    "        ]))\n",
    "\n",
    "grid = gpd.GeoDataFrame({'geometry':polygons})\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "from matplotlib import colormaps\n",
    "\n",
    "fig = plt.figure(dpi=150)\n",
    "ax = fig.add_subplot(projection=ccrs.Robinson())\n",
    "ax.coastlines(lw=0.2)\n",
    "\n",
    "shape = (len(pop_df.y.unique()), len(pop_df.x.unique()))\n",
    "\n",
    "pop_df[\"n\"] = pop_df.population\n",
    "pop_df.loc[pd.notna(pop_df[\"country\"]),\"n\"] = 0\n",
    "\n",
    "n = np.array(pop_df.n).reshape(shape)\n",
    "\n",
    "mesh=ax.pcolormesh(\n",
    "    pop_df.x.unique(), \n",
    "    pop_df.y.unique(), \n",
    "    n, \n",
    "    cmap=colormaps['magma_r'],\n",
    "    norm=mpl.colors.LogNorm(),\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
